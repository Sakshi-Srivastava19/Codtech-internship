# -*- coding: utf-8 -*-
"""Task-2_Speech-Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qANF1bzLgUB3n39pfJQF6A3RB8UcM7ii

# **CODTECH INTERNSHIP - by SAKSHI SIVASTAVA**

# **TASK -2 SPEECH RECOGNITION SYSTEM**
 **BUILD A BASIC SPEECH-TO-TEXT SYSTEM USING PRE-TRAINED MODELS AND LIBRARIES LIKE SPEECHRECOGNITION OR WAV2VEC.**
"""

pip install transformers torchaudio librosa soundfile

from transformers import pipeline
import torchaudio

# Load the model
asr = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h")

# Load your audio file (16kHz mono WAV file)
def transcribe_audio(audio_path):
    speech, rate = torchaudio.load(audio_path)
    if rate != 16000:
        transform = torchaudio.transforms.Resample(orig_freq=rate, new_freq=16000)
        speech = transform(speech)
    result = asr(speech[0].numpy())
    print("Transcribed Text:", result["text"])

# Call the function
transcribe_audio("BAK.wav")

from transformers import pipeline
import torchaudio

# Load the model
asr = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h")

# Load your audio file (16kHz mono WAV file)
def transcribe_audio(audio_path):
    speech, rate = torchaudio.load(audio_path)
    if rate != 16000:
        transform = torchaudio.transforms.Resample(orig_freq=rate, new_freq=16000)
        speech = transform(speech)
    result = asr(speech[0].numpy())
    print("Transcribed Text:", result["text"])

# Call the function
transcribe_audio("BAK.wav")